{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Copy of assignment5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReDaMhiE_vNY",
        "outputId": "dd58bf94-65d3-4476-cfdc-6afff9e9de40"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7k3KIY6ZDwdc"
      },
      "source": [
        "# Suppress Warnings\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5DTUTpX_ryo"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import collections\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.optim as optim\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import math"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9w0CJXvI6st",
        "outputId": "8fa7a440-1359-4389-f724-17954258a94a"
      },
      "source": [
        "device = torch.device(\"cuda\")\n",
        "torch.manual_seed(0)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f5bb8c7fba0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3MukxvI_ry4"
      },
      "source": [
        "lan_codes = ['en', 'es', 'pt', 'gl', 'eu', 'ca', 'fr', 'it', 'de']\n",
        "Languages = ['English', 'Spanish', 'Portuguese', 'Galician', 'Basque', 'Catalan', 'French', 'Italian', 'German']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZAs52bY_ry7"
      },
      "source": [
        "## Load the Data, Calculate Vocabulary and Perplexity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WQPG4VtJCk0"
      },
      "source": [
        "def load_data(filename):\n",
        "    data = pd.read_csv(filename, header=None, sep='\\t', quoting=3)\n",
        "    data.columns = ['lan','tweet']\n",
        "    return data"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2ZWFFUhAsQy"
      },
      "source": [
        "def get_freq(data, vocab):\n",
        "    freq = np.zeros(len(vocab))\n",
        "    for tweet in data.tweet:\n",
        "        for char in tweet:\n",
        "            if char in vocab:\n",
        "                freq[vocab.index(char)] += 1\n",
        "            else:\n",
        "                freq[vocab.index('<N>')] += 1\n",
        "        freq[vocab.index('</S>')] += 1\n",
        "    return freq"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPL7TgL5_ry9",
        "outputId": "a92e6e34-8af2-4e15-85a4-efab1a431d2c"
      },
      "source": [
        "class Data():\n",
        "    def __init__(self):\n",
        "        self.train = load_data('/content/drive/MyDrive/Data/train.tsv')\n",
        "        self.val = load_data('/content/drive/MyDrive/Data/val.tsv')\n",
        "        self.test = load_data('/content/drive/MyDrive/Data/test.tsv')\n",
        "        self.get_vocab()\n",
        "        self.train_freq = get_freq(self.train, self.vocab)\n",
        "        self.val_freq = get_freq(self.val, self.vocab)\n",
        "\n",
        "    def get_vocab(self):\n",
        "        chars = [i for ele in self.train.tweet.to_list() for i in ele]\n",
        "        most_common = Counter(chars).most_common()\n",
        "        char_limit = 10\n",
        "        for k in range(len(most_common)):\n",
        "            if most_common[k][1] < char_limit:\n",
        "                break\n",
        "\n",
        "        vocab = [i[0] for i in most_common[:k]]\n",
        "        vocab.insert(0,'<S>')   # start token\n",
        "        vocab.insert(0,'</S>')  # end token\n",
        "        vocab.insert(0,'<N>')   # out-of-vocabulary token\n",
        "        \n",
        "        self.vocab = vocab\n",
        "    \n",
        "    def get_perplexity(self):\n",
        "        train_freq = self.train_freq / self.train_freq.sum()\n",
        "        val_freq = self.val_freq / self.val_freq.sum()\n",
        "        train_freq[self.vocab.index('<S>')] = 1\n",
        "        return np.exp(-(val_freq * np.log(train_freq)).sum())\n",
        "\n",
        "# Load Data\n",
        "data = Data()\n",
        "print('Size of the vocabulary: %d characters' % len(data.vocab))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of the vocabulary: 509 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkWwb7sy_ry-",
        "outputId": "d8c5fbdb-00a7-4e0a-a4da-a9292f75a4bd"
      },
      "source": [
        "preplexity = data.get_perplexity()\n",
        "print('Perplexity measurement is %.2f' % preplexity)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Perplexity measurement is 34.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nItvqmAx_ry_",
        "outputId": "d4e7e54a-4205-4d21-cae8-55b9cbcb48ea"
      },
      "source": [
        "print('Percent of Invalid Characters - Train: %.5f%%' \n",
        "    % ((data.train_freq[data.vocab.index('<N>')] / data.train_freq.sum()) * 100.0))\n",
        "print('Percent of Invalid Characters - Val: %.5f%%' \n",
        "    % ((data.val_freq[data.vocab.index('<N>')] / data.val_freq.sum()) * 100.0))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percent of Invalid Characters - Train: 0.04622%\n",
            "Percent of Invalid Characters - Val: 0.05987%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjxwQOWXoXP2"
      },
      "source": [
        "## Process the data for the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vhfai9kJJP0f"
      },
      "source": [
        "def get_data_loader(tweets, lans, batch_size, shuffle=False):\n",
        "    data_tensor = torch.tensor(tweets, dtype=torch.long, device=device)\n",
        "    label_tensor = torch.tensor(lans, dtype=torch.long, device=device)\n",
        "    train_dataset = TensorDataset(data_tensor, label_tensor)\n",
        "    return DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=shuffle) \n",
        "\n",
        "def data_encoding(data, vocab, languages):\n",
        "    tweets = tweet_enconding(data.tweet, vocab)\n",
        "    langs = lang_encoding(data.lan, languages)\n",
        "    return tweets, langs\n",
        "\n",
        "def tweet_enconding(tweets, vocab, tweet_length=282):\n",
        "    encoded = np.zeros((len(tweets), tweet_length))\n",
        "    for t, tweet in enumerate(tweets):\n",
        "        encoded[t][0] = vocab.index('<S>')\n",
        "        for char in range(1, tweet_length-1):\n",
        "            if char < len(tweet) and tweet[char] in vocab:\n",
        "                encoded[t][char] = vocab.index(tweet[char])\n",
        "            elif char < len(tweet):\n",
        "                encoded[t][char] = vocab.index('<N>')\n",
        "            else:\n",
        "                encoded[t][char] = vocab.index('</S>')\n",
        "        encoded[t][tweet_length-1] = vocab.index('</S>')\n",
        "    return encoded\n",
        "\n",
        "def lang_encoding(labels, languages, tweet_length=282):\n",
        "    encoded = np.zeros((len(labels), tweet_length))\n",
        "    for l, lang in enumerate(labels):\n",
        "        idx = languages.index(lang)\n",
        "        for char in range(0, tweet_length):\n",
        "            encoded[l][char] = idx\n",
        "    return encoded"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "yboBh1nH_rzD"
      },
      "source": [
        "# this cell takes a few minutes to run\n",
        "train_tweets, train_lans = data_encoding(data.train, data.vocab, lan_codes)\n",
        "val_tweets, val_lans = data_encoding(data.val, data.vocab, lan_codes)\n",
        "test_tweets, test_lans = data_encoding(data.test, data.vocab, lan_codes)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv8Bhv5p_rzD"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rzuw-GNJGFl"
      },
      "source": [
        "def train(model, train_loader, optimizer, epochs, verbose=False):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for data, label in train_loader:\n",
        "            data, label = data.to(device), label.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output, hidden = model(data, label)\n",
        "            loss = loss_function(output, label)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        if verbose:\n",
        "          print('Epoch: %d \\tLoss: %.6f' % (epoch, loss.item()))\n",
        "\n",
        "def test(model, test_loader, pad):\n",
        "    model.eval()\n",
        "    loss = 0\n",
        "    perp = 0\n",
        "    with torch.no_grad():\n",
        "        for data, label in test_loader:\n",
        "            data, label = data.to(device), label.to(device)\n",
        "            output, hidden = model(data, label)\n",
        "            loss += loss_function(output, label).item()\n",
        "            perp += math.exp(F.cross_entropy(output.view(-1, 509), label.view(-1), ignore_index=pad))\n",
        "    return loss, perp"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bnc5cNKA_rzD"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, initial_weights):\n",
        "        super(RNN, self).__init__()\n",
        "        self.char_encoder = nn.Embedding(509, 14).cuda()\n",
        "        self.lang_encoder = nn.Embedding(9, 4).cuda()\n",
        "        self.gru = nn.GRU(18, 50).cuda()\n",
        "        self.fc1 = nn.Linear(50, 14).cuda()\n",
        "        self.fc2 = nn.Linear(14, 509).cuda()\n",
        "        self.softmax = nn.LogSoftmax().cuda()\n",
        "        self.criterion = nn.NLLLoss(initial_weights, size_average=False).cuda()\n",
        "        self.initialize_fc2\n",
        "\n",
        "    def initialize_fc2():\n",
        "        self.fc2.weight = self.char_encoder.weight\n",
        "        self.fc2.bias.data.zero_()\n",
        "\n",
        "    def forward(self, tweets, lang, hidden=None):\n",
        "        x = torch.cat((self.lang_encoder(lang), self.char_encoder(tweets)), -1)\n",
        "        x, h = self.gru(x, hidden)\n",
        "        x = F.tanh(self.fc1(x))\n",
        "        return self.fc2(x), h\n",
        "\n",
        "initial = torch.ones(509)\n",
        "initial[data.vocab.index('</S>')] = 0\n",
        "model = RNN(initial)"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Gyg1xfFR78h"
      },
      "source": [
        "def loss_function(guess, label):\n",
        "  return model.criterion(model.softmax(guess.view(-1, 509)), label.view(-1))"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHq0RFOK_rzE"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "EPOCHS = 20\n",
        "LEARNING_RATE = 0.001\n",
        "DECAY = 0.0005"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udkMonjSDaCQ"
      },
      "source": [
        "train_loader = get_data_loader(train_tweets, train_lans, BATCH_SIZE, shuffle=True)\n",
        "val_loader = get_data_loader(val_tweets, val_lans, BATCH_SIZE)"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuPEsfRV_rzE"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=DECAY)"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdeQHPsd_rzF",
        "outputId": "9fe42f38-e6c0-4f13-dad0-723f55b3bcb6"
      },
      "source": [
        "train(model, train_loader, optimizer, EPOCHS, verbose=True)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 \tLoss: 591.691345\n",
            "Epoch: 1 \tLoss: 67.239189\n",
            "Epoch: 2 \tLoss: 24.346916\n",
            "Epoch: 3 \tLoss: 13.931030\n",
            "Epoch: 4 \tLoss: 6.333050\n",
            "Epoch: 5 \tLoss: 4.023886\n",
            "Epoch: 6 \tLoss: 1.196495\n",
            "Epoch: 7 \tLoss: 1.045545\n",
            "Epoch: 8 \tLoss: 0.601413\n",
            "Epoch: 9 \tLoss: 0.419781\n",
            "Epoch: 10 \tLoss: 0.209214\n",
            "Epoch: 11 \tLoss: 0.085225\n",
            "Epoch: 12 \tLoss: 0.026110\n",
            "Epoch: 13 \tLoss: 0.038447\n",
            "Epoch: 14 \tLoss: 0.022037\n",
            "Epoch: 15 \tLoss: 0.012356\n",
            "Epoch: 16 \tLoss: 0.009294\n",
            "Epoch: 17 \tLoss: 0.026798\n",
            "Epoch: 18 \tLoss: 0.016216\n",
            "Epoch: 19 \tLoss: 0.005877\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrJcMSgF_rzG",
        "outputId": "83c9159d-4cdf-4c75-a188-6cf9b8cbe3ce"
      },
      "source": [
        "test(model, val_loader, data.vocab.index('</S>'))"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.8001482766121626, 184.00014343843245)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDCHK5fo_rzJ"
      },
      "source": [
        "tweets_test = torch.tensor(test_tweets, dtype=torch.long, device=device)\n",
        "language_val = torch.tensor(test_lans, dtype=torch.long, device=device)"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_whDFHF_rzK",
        "outputId": "70abe2a6-12f3-4c80-b935-09e7797eb6c9"
      },
      "source": [
        "def predict(model, device, data):\n",
        "    '''\n",
        "    lan - language id (0-8)\n",
        "    '''\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for lan in range(9):\n",
        "            label = torch.ones(data.size(), dtype=torch.long)*lan\n",
        "            data, label = data.to(device), label.to(device)\n",
        "            output, hidden = model(data, label)\n",
        "            #convert to numpy\n",
        "            data_np = data.cpu().numpy()\n",
        "            output_np = output.cpu().numpy()\n",
        "\n",
        "            # calculate log prob for each letter of sequence (using output matrix)     \n",
        "            prob = np.zeros(data_np.shape)\n",
        "            for batch in range(output_np.shape[0]):\n",
        "                for char in range(output_np.shape[1]):\n",
        "                    prob[batch, char] = output_np[batch, char, data_np[batch, char]]\n",
        "\n",
        "            if lan == 0:\n",
        "                total_prob = np.sum(prob, axis=1)\n",
        "            else:\n",
        "                total_prob = np.vstack((np.sum(prob, axis=1),total_prob))\n",
        "        \n",
        "        # Choose language with highest character probability\n",
        "        output = np.argmax(total_prob,axis=0)\n",
        "        return output\n",
        "\n",
        "pred = predict(model, device, tweets_test[:5000,:])\n",
        "print(f'Percent Correct: {np.sum(pred == test_lans[:5000,0])/pred.shape[0]*100}')"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percent Correct: 19.88\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaGa7WgZWGKY",
        "outputId": "af11b8c8-a85f-4bfb-c9fb-5072a16775e5"
      },
      "source": [
        "def Metrics(preds, labs, show=True):\n",
        "  \"\"\"Print precision, recall and F1 for each language.\n",
        "  Assumes a single language per example, i.e. no code switching.\n",
        "  Args:\n",
        "    preds: list of predictions\n",
        "    labs: list of labels\n",
        "    show: flag to toggle printing\n",
        "  \"\"\"\n",
        "  all_langs = set(preds + labs)\n",
        "  preds = np.array(preds)\n",
        "  labs = np.array(labs)\n",
        "  label_totals = collections.Counter(labs)\n",
        "  pred_totals = collections.Counter(preds)\n",
        "  confusion_matrix = collections.Counter(zip(preds, labs))\n",
        "  num_correct = 0\n",
        "  for lang in all_langs:\n",
        "    num_correct += confusion_matrix[(lang, lang)]\n",
        "  acc = num_correct / float(len(preds))\n",
        "  print('accuracy = {0:.3f}'.format(acc))\n",
        "  if show:\n",
        "    print(' Lang     Prec.   Rec.   F1')\n",
        "    print('------------------------------')\n",
        "  scores = []\n",
        "  fmt_str = '  {0:6}  {1:6.2f} {2:6.2f} {3:6.2f}'\n",
        "  for lang in sorted(all_langs):\n",
        "    idx = preds == lang\n",
        "    total = max(1.0, pred_totals[lang])\n",
        "    precision = 100.0 * confusion_matrix[(lang, lang)] / total\n",
        "    idx = labs == lang\n",
        "    total = max(1.0, label_totals[lang])\n",
        "    recall = 100.0 * confusion_matrix[(lang, lang)] / total\n",
        "    if precision + recall == 0.0:\n",
        "      f1 = 0.0\n",
        "    else:\n",
        "      f1 = 2.0 * precision * recall / (precision + recall)\n",
        "    scores.append([precision, recall, f1])\n",
        "    if show:\n",
        "      print(fmt_str.format(lang, precision, recall, f1))\n",
        "  totals = np.array(scores).mean(axis=0)\n",
        "  if show:\n",
        "    print('------------------------------')\n",
        "    print(fmt_str.format('Total:', totals[0], totals[1], totals[2]))\n",
        "  return totals[2]\n",
        "\n",
        "class MovingAvg(object):\n",
        "  def __init__(self, p):\n",
        "    self.val = None\n",
        "    self.p = p\n",
        "\n",
        "  def Update(self, v):\n",
        "    if self.val is None:\n",
        "      self.val = v\n",
        "      return v\n",
        "    self.val = self.p * self.val + (1.0 - self.p) * v\n",
        "    return self.val\n",
        "\n",
        "Metrics(pred, test_lans[:5000,0])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy = 0.199\n",
            "  Lang     Prec.   Rec.   F1\n",
            " ------------------------------\n",
            "      0.0   30.16  57.34  39.53\n",
            "      1.0    0.00   0.00   0.00\n",
            "      2.0    2.78  10.91   4.43\n",
            "      3.0    0.00   0.00   0.00\n",
            "      4.0    5.91  45.83  10.46\n",
            "      5.0    0.00   0.00   0.00\n",
            "      6.0    3.83  16.88   6.25\n",
            "      7.0    0.00   0.00   0.00\n",
            "      8.0    0.00   0.00   0.00\n",
            " ------------------------------\n",
            "   Total:    2.85   8.73   4.04\n",
            "4.044627144291371\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}